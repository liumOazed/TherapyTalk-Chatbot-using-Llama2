{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\us\\anaconda3\\envs\\mindbot\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate # with this we can create a prompt\n",
    "from langchain.chains import RetrievalQA # with this we can ask questions to the model\n",
    "from langchain.embeddings import HuggingFaceEmbeddings # with this we can convert text to vector\n",
    "from langchain.vectorstores import Pinecone # with this we can store the vector\n",
    "import pinecone \n",
    "from langchain.document_loaders import PyPDFLoader,JSONLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # With this we can split the text into smaller chunks\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers   \n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load pdf and then convert it to JSON\n",
    "# import json\n",
    "# from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# def load_pdf(data):\n",
    "#     loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "#     documents = []\n",
    "#     for pdf_file in loader.load():\n",
    "#         pdf_data = {}\n",
    "#         pdf_data['main_query'] = pdf_file.metadata.get('main_query', '')  # Access metadata directly\n",
    "#         pdf_data['context_queries'] = [pdf_file.page_content]  # Access page content directly\n",
    "#         documents.append(pdf_data)\n",
    "#     return json.dumps(documents)\n",
    "# extracted_data = load_pdf(\"E:/Code/TherapyTalk-Chatbot-using-Llama2/data/\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from pdf\n",
    "def load_pdf(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract data from json\n",
    "# def load_json(data, jq_schema):\n",
    "#     loader = DirectoryLoader(data,\n",
    "#                              glob=\"*.json\",\n",
    "#                              loader_cls=JSONLoader,\n",
    "#                              loader_kwargs={'jq_schema': jq_schema})\n",
    "    \n",
    "#     documents = loader.load()\n",
    "#     return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# def run_jq(command):\n",
    "#     jq_path = r'C:\\jq\\jq\\jq-win64.exe'  # Ensure the correct path\n",
    "#     process = subprocess.Popen([jq_path, '-r', command], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "#     output, error = process.communicate()\n",
    "#     if process.returncode != 0:\n",
    "#         raise Exception(f'jq command failed with error: {error.decode()}')\n",
    "#     return output.decode()\n",
    "\n",
    "# # get output\n",
    "# jq_schema = '{\"main_query\": .main_query, \"context_queries\": .context_queries}'\n",
    "# output = run_jq(jq_schema)\n",
    "\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create subprocess to run jq\n",
    "# import subprocess\n",
    "\n",
    "# def run_jq(command,json_file):\n",
    "#     jq_path = 'C:\\jq\\jq\\jq-win64.exe'  # Replace with the actual path to your jq executable\n",
    "#     process = subprocess.Popen([jq_path, '-r', command], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "#     output, error = process.communicate()\n",
    "#     if process.returncode != 0:\n",
    "#         raise Exception(f'jq command failed with error: {error.decode()}')\n",
    "#     return output.decode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Construct the jq command to extract main_query and context_queries\n",
    "# jq_command = '.main_query, .context_queries'\n",
    "# json_file = 'data/test.json'  # Path to your JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the jq command using the run_jq function\n",
    "# try:\n",
    "#     output = run_jq(jq_command, json_file)\n",
    "#     # print(output)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data= load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"wants to know what it thinks is most important to them. It's a race between Facebook and Google to\\nfigure it out. One minute your brand could be popping up at the top of a user’s page; the next it could be\\nburied six pages down. Facebook may decide that sharing is a much stronger call to action and\\nbrandendorsement than liking. If your content happens to elicit many shares, you’re golden. But then\\nFacebook could change its mind and decide that likes are actually as valuable if not more so than\\nshares. Your content doesn’t usually get that many likes. Now what? The key to great marketing is\\nremembering that even though you’re all about your brand, your customer is not. As with any first date,\\ngetting a second date depends on you doing your best to learn more about what the other person is\\ninterested in. In the end, boxing and dating are really not that different. After all, the goal is to score.\\nSometimes the score is measured in points, and sometimes in a marriage proposal. You won’t win if\\nyou play your most aggressive move first. If the CMO of this boot company knows only as much about\\nsocial media as the average businessperson, as soon as she sees that first status update she’s going\\nto storm up to you and question the living crap out of it. What does 30 Rock have to do with our boot\\ncompany? How off-brand can you get? Why are we doing this? How does this sell more boots? And\\nyour answer will be, it doesn’t. Yet. As the C MO of the boot company stands there looking, at best,\\ncurious and, at worst, furious, you will calmly point to the analytics. The uptick in engagement tells\\nFacebook that this brand matters to people. So when you put out your next piece of content, a\\nfifteen-second user-generated video of people showing off their boots, Facebook makes sure your\\ncustomers see it in their News Feed. Again, the piece isn’t selling anything. Nor is the next one, a\\nValentine’s Day card that doesn't show a single boot. The next one is a Valentine's Day card with a\\npicture of you and your family. Facebook can give a detailed and nuanced understanding of the people\\nwho buy our products. By testing and jabbing and giving, we learn what they find entertaining. Content\\nthatentertains sees engagement. The more you give, the more you really will get them. And if you put\\nout three or four pieces of content thatdon’t sell anything, either, like this:Third jab: Post—A\\nfifteen-second video about rock climbing. Fourth jab: Poll—“Would you rather wear your boots in the\\nsummer or the winter?” On any other platform, where your posts are entirely public, every jab hits\\neveryone in the face. On Facebook, however, you can be extremely selective, customizing your jabs.\\nContent that sees engagement tells Facebook and the rest of the world that your customers care about\\nyour brand. When you finally do put out something that would directly benefit your bottom line—a\\ncoupon, a free-shipping offer, or some other call to action—4 percent of your community sees it instead\\nof a half percent. Targeting your posts is a strategy to keep in mind when you’re jabbing; it’s flat-out\\nessential when you're throwing a right hook. Let’'s say you're a national fashion retailer, and today is\\nBlack Friday. You’ve created a piece that highlights one of your most coveted purses. You know that\\nthe buyers of that purse are generally twenty-five-year-old females. Does it make any sense to send\\nthat content about a purse to your fifty-five year-old male customers? Of course not. For any jab or right\\nhook to have impact, it has to speak to the consumer and hit his or her emotional center. By speaking\\ndirectly to the right demographic, you’ve increased the probability that people will engage with that\\ncontent. You go even further and design the content so that it goes out to consumers in Texas in the\\nshape of Texas, and the content that goes to New Jersey is in theshape of New Jersey, and so on and\\nso forth for any of the states whose residents have a particularly strong streak of state pride. With very\\nlittle lead time, a retailer can create two distinct pieces of content. The retailer can then watch in real\\ntime to see how the recipients respond. To accomplish the same thing on television, a national retailer\\nmight create two different TV spots targeting different demographics. It makes sure the content shows\\nup in more people’s stream, which therefore allows the retailer to show its content over and over again\\nto an ever-larger audience without having to pay any more for it. It's worth taking a step back and\\nexamining the cost-effectiveness of this scenario. The creative team would have to develop the ads\\nweeks before they ran. Typically, the spot would need to run enough times so that the retailer’s desired\\nreach population would have seen the spot three times. It would cost the retailer between $7,000 and\\n$13,000 to reach this audience. And if it wanted to run more content, it would haveto pay all over again.\\nWhich scenario sounds more time- and cost-efficient to you? Which scenario does you prefer? On\\naverage, the cost of running an ad on the right side of the page on Facebook runs the gamut between\\n$.50 to $1.50 per like. Depending on the specificityof your targeting, the length of your campaign, and\\nyour budget it’s possible to acquire likes for as low as $.10 and as high as several dollars. A dollar\\n\", metadata={'source': 'data\\\\input_rag.pdf', 'page': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunk = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the embedding model\n",
    "def download_embedding_model():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 384\n"
     ]
    }
   ],
   "source": [
    "query_results = embeddings.embed_query(\"Hello World\")\n",
    "print(\"length\", len(query_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pinecone\n",
    "from pinecone import Pinecone\n",
    "PINECONE_API_KEY = \"e5b0b3f3-d5c3-4f55-8053-976ad38419f6\"\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"mindbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'dimension': 384,\n",
       "              'host': 'mindbot-caeac3f.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'mindbot',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating embeddings for each of the text chunks and store them in pinecone. (This is our knowledge base) \n",
    "docsearch = PineconeVectorStore.from_texts([t.page_content for t in text_chunks], index_name='mindbot', embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we already have an index we can load it (This is also checking ranked results)\n",
    "docsearch = PineconeVectorStore.from_existing_index( index_name='mindbot', embedding=embeddings) # with this we can load the vector\n",
    "\n",
    "query = \"What is digital marketing\"\n",
    "\n",
    "docs = docsearch.similarity_search(query, k=3)# here k is the number of results we want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"managers hoping to benefit from digital content marketing, we advocate further investments into\\ntechnologies that improve the selling firm’s ability to target content based on the customer■'s\\nidiosyncratic needs at different journey stages. Gartner found that, when considering a relevant content\"), Document(page_content='marketing is the marketing of a business or brand through the sharing of educational, entertaining, or\\ninsightful information that will help consumers enrich their lives. It is not about forcing a sales pitch on\\nconsumers but about helping them move towards the best option for themselves (which may or may not\\nbe buying the marketers brand) (Ruffolo 2017.) There are many ways customer value can be created.'), Document(page_content='literature strongly posits brand or brand-related content, this is not always the best way to go about\\ndeveloping a digital content distribution strategy. This is the first study to demonstrate the positive effect\\nof DCM on firm engagement in the form of lead acquisition. DCM does not require intelligence of\\ncustomer needs at different journey stages or level of customer knowledge. At the same time, the\\nbaseline DCM approach is. unlikely to be as effective in generating engagement as more')]\n"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Prompt Template\n",
    "promp_template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know. Do not make up an answer.\n",
    "context: {context}\n",
    "question: {question}\n",
    "Only return the helpful answer and information about the context. Do not make up an answer.\n",
    "Helpful Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Prompt Template\n",
    "prompt = PromptTemplate(template=promp_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs = {\"prompt\": prompt} # Created this chain type argument because I will be using Retrieval QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading llm model\n",
    "llm = CTransformers(model=\"model\\llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                    model_type=\"llama\",\n",
    "                    config={\"max_new_tokens\": 512,\n",
    "                            \"temperature\": 0.8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining Retriever Class below:\n",
    "\n",
    "Importing necessary modules and classes:\n",
    "Python\n",
    "```\n",
    "from langchain.schema.retriever import BaseRetriever\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "from pydantic import BaseModel\n",
    "```\n",
    "These lines import the necessary modules and classes. BaseRetriever is the base class for all retrievers, List is a typing construct that denotes a list, Document is a class that represents a document, and BaseModel is a base class for Pydantic models.\n",
    "\n",
    "<b>Defining the PineconeRetriever class:</b>\n",
    "```\n",
    "class PineconeRetriever(BaseRetriever, BaseModel):\n",
    "    pinecone_vector_store: PineconeVectorStore\n",
    "```\n",
    "\n",
    "This line defines the PineconeRetriever class which inherits from both BaseRetriever and BaseModel. It has a single attribute pinecone_vector_store of type PineconeVectorStore.\n",
    "\n",
    "<b>Defining the constructor:</b>\n",
    "```\n",
    "def __init__(self, pinecone_vector_store: PineconeVectorStore, **data):\n",
    "    super().__init__(pinecone_vector_store=pinecone_vector_store, **data)\n",
    "```\n",
    "The constructor takes two arguments: pinecone_vector_store and **data. It calls the constructor of the superclass with these arguments.\n",
    "\n",
    "<b>Defining the _get_relevant_documents method:</b>\n",
    "```\n",
    "\n",
    "def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "    return self.pinecone_vector_store.similarity_search(query)\n",
    "```\n",
    "This method takes a query string and returns a list of Document objects that are relevant to the query. It does this by calling the similarity_search method of the pinecone_vector_store object.\n",
    "\n",
    "<b>Defining the _aget_relevant_documents method:</b>\n",
    "```\n",
    "async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "    return self.pinecone_vector_store.similarity_search(query)\n",
    "```\n",
    "This method is the asynchronous version of _get_relevant_documents. It does the same thing but in an asynchronous manner. This can be useful when dealing with IO-bound tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining retriever\n",
    "from langchain.schema.retriever import BaseRetriever\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class PineconeRetriever(BaseRetriever, BaseModel):\n",
    "    pinecone_vector_store: PineconeVectorStore\n",
    "\n",
    "    def __init__(self, pinecone_vector_store: PineconeVectorStore, **data):\n",
    "        super().__init__(pinecone_vector_store=pinecone_vector_store, **data)\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        return self.pinecone_vector_store.similarity_search(query)\n",
    "\n",
    "    async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        return self.pinecone_vector_store.similarity_search(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PineconeRetriever object\n",
    "pinecone_retriever = PineconeRetriever(docsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Retrieval QA  Object\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=pinecone_retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Hi What is SEO', 'result': \"The answer question. \\nI don's on brand- Content Marketing and informational\\nYou can be removedhelpfulfill in content marketing the content on consumers are used to make-Google Ping search engine optimization,\\ncontent marketing and Google Pandaid=\\nI do not helpful answer is a content marketing customer rewards competitive vs. 0\\nIf you have an empirical or not helpfulAnswer: YesHelpfulness, Patelcome in the impact of keywords and Content marketing and content marketing a systematic content marketing\\nNo help@\\nContent Marketing on social media use of content marketing your answer.  I can help\\nA\\nTo improve\\nContent Marketers for customers’\\nGoogle's on customer experience, but do not helpful answer to get outstanding\\nContent marketing relevant (I don' Content quality and social media usage and quality on the question- You can provide your SEOurseofficacy and informative content. (TrueHelpful Answer:\\nThe answer_ Do not helpful  A case of this question!\\nGoogle uses. Google does not an empirical marketing questionable content marketing content type on consumers, Patelations and customer involvement types of content marketing\\nI don's and consumer engagement and content marketing a content and Content marketing a system and employee advocacy versus competit is a case study finds that' I cannot determine if you are there is not Helpfulfillers's to get outcomes to be helpful answer questions about\\nTo find yourself?We cannot answered\\nI don'The best practices on consumer engagement and social media adoptionality, HHelpfulfilling content marketing\\nIn order for customer value creation of the case studies to provide context in answering. (Please provide a systematic and product placement,  Yes, 0401280. The question\\nYou have any changes on consumer involvement on social media\\nUnfortunately, I don'! Helpful content marketing.\", 'source_documents': [Document(page_content='Engine Optimization include consistent use of keywords and the strategic employment of key words.\\nHowever, poor quality content infused with keywords will not work (Patel 2015.) The search engine\\nconsiders all results ranked based on what the search engine consider most relevant to consumers\\n(Search Engine Land 2018) In 2010 Google noticed that the quality of their search result were falling.\\nGoogle developed Google Panda, an algorithm which weeds out poor quality, thin content and rewards'), Document(page_content='new customers and more team coordination. Content Marketing provides the content that Search\\nEngine Optimization demands (Patel 2015.) Content Marketing is proving more effective than traditional\\nmarketing (i-SCOOP 2018) Google actively seeks high quality content with the most relevant\\ninformation for the search enquiries of their users. Content marketing tells Google that you are\\nimportant and authoritative in your industry and moves you higher in the search result standing. Search'), Document(page_content='the use of unique, compelling content. Social Media websites are considered one of the most beneficial\\nresources a business can have. A business who does not use Content Marketing gets left behind.\\nSuccessful Content Marketing requires exceptional skill and expertise. To get outstanding results\\nrequires exceptionalskill and expertise (Ruffolo 2017.) Not all Content Marketing is successful. Content'), Document(page_content='Science, 49, 51–70. Chaffey, D., & Patron, M. (2012). From web analytics to digital marketing\\noptimization: At This American Life, Content Marketing Institute. Malthouse, E. C., Haenlein, M., Skiera,\\nB., Wege, E., & Zhang, M (2013). Managing customer relationships in the social media era: Introducing\\nthe social CRM house. Cheng, M, Liu, J., Qi, J. & Wan, F. (2021). Differential effects of firm generated\\ncontent. Cortez, R., Johnston, W., & Dastidar, A. (2023) Managing the content of LinkedIn')]}\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(f\"Ask your question: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    else:\n",
    "        result = qa({\"query\": user_input})\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
